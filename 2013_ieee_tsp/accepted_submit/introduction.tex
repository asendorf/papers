% Old version
%\IEEEPARstart{M}{any} signal processing  \cite{scharf1991statistical} and machine learning \cite{friedman2001elements} applications involve the task of detecting a signal of interest buried in high dimensional noise. A matched subspace detector (MSD) is commonly used to solve this problem when the target signal is assumed to lie in a low-rank subspace.  The low-rank signal buried in noise model is ubiquitous in signal processing. See for example, \cite{besson2006cfar,bandiera2007glrt, bandiera2007adaptive}, which determine if a snapshot is noise-only or if it contains target echoes, \cite{maris2003resampling, soong1995principal}, which examine source localization in electroencephalography (EEG) and magnetoencephalography (MEG) data, and \cite{besson2005matched}, which examines low-rank signal recovery in radar, sonar, and communications applications. The performance of such detectors when the signal subspace is known a priori has been extensively studied (see, for example, \cite{besson2006cfar,scharf1994matched,jin2005cfar,mcwhorter2003matched, vincent2008matched} to list a few). This paper considers the performance of a MSD in the less studied setting where the signal subspace is unknown and must be estimated from finite, noisy, signal-bearing training data.

\IEEEPARstart{M}{any} signal processing  \cite{scharf1991statistical} and machine learning \cite{friedman2001elements} applications involve the task of detecting a signal of interest buried in high dimensional noise. A matched subspace detector (MSD) is commonly used to solve this problem when the target signal is assumed to lie in a low-rank subspace.  The low-rank signal buried in noise model is ubiquitous in signal processing. In array processing, \cite{besson2005matched} and \cite{besson2006cfar} use multiple array snapshots to detect a low-rank signal in the presence of both interference and noise when the noise power is known and unknown, respectively. Similarly in adaptive radar detection, \cite{bandiera2007adaptive} and \cite{bandiera2007glrt} adaptively detect distributed low-rank targets given multiple snapshots of primary (signal plus noise) and secondary (noise only) data under partially homogeneous and homogeneous noise assumptions, respectively. Low rank signal models are also used in electroencephalography (EEG) and magnetoencephalography (MEG) source localization as in \cite{maris2003resampling} and \cite{soong1995principal}, respectively. In \cite{besson2005matched,besson2006cfar,bandiera2007adaptive,bandiera2007glrt}, the signal subspace is known. The performance of a MSD when the signal subspace is known was studied in \cite{scharf1994matched} and \cite{vincent2008matched} under deterministic signal assumptions and in \cite{mcwhorter2003matched} and \cite{jin2005cfar} under stochastic signal assumptions. This paper considers the performance of a MSD in the less studied setting where the signal subspace is unknown and must be estimated from finite, noisy, signal-bearing training data.

The setting we have in mind arises from machine learning related applications where the low-rank signal model is reasonable but the signal subspace is not parameterizable. This is in contrast to the array processing applications that motivated the original MSD work \cite{scharf1994matched} where the signal subspace is explicitly parameterizable whenever the array geometry is known. The inferential problem is made tractable by the availability of a training dataset consisting of signal-bearing observations that have been collected in a variety of representative experimental (and thus noisy) conditions. In such a scenario,  the truncated eigen-decomposition of the sample covariance matrix of this training data yields an estimate of the unknown low-rank signal subspace, which may then be used for signal versus noise discrimination.

An illustrating example of this is the classical problem of handwriting recognition \cite[Chapter 10]{elden2007matrix} where a MSD can be used to determine if an area of an image contains a digit $0-9$ or is pure noise. Here, a database \cite{hwritingurl}, containing a large number of handwritten samples of each of the digits written by many different writers, is used to form a low-rank subspace estimate of each digit. The samples are noisy because of digitization effects and the inherent variation between writers. A nearest-subspace classifier based on retaining only the first few ($10-12$, in this example) principal components (or leading eigenvectors of the digit's training data sample covariance matrix) associated with each digit yields greater than 93\% classification performance \cite[Table 10.1, pp. 121]{elden2007matrix}, indicating that the low-rank signal buried in noise model is appropriate. The motivating setting described also arises in the context of image or wavefront recognition applications (e.g. license plate character recognition) where the target and the camera are separated by a dynamic random medium and in hyperspectral imaging based anomaly detection  \cite{thai2002invariant,healey1999models,kwon2006kernel} relative to a statistically stationary scene (e.g. toxic gas detection). Here too, a practitioner might have access to training samples collected over a variety of experimental conditions and might employ the MSD in a similar manner.

In these applications, the standard plug-in detector, which substitutes an estimate of the signal subspace into the expression for the oracle MSD that was derived assuming the subspace is perfectly known, realizes a performance loss because additive noise and finite training data decrease the accuracy of the estimated subspace. This motivates questions such as: What is the expected plug-in detector performance? Is it possible to avoid some of this performance loss? How does the estimation of the signal subspace dimension influence detector  performance? Is the ``play-it-safe''  overestimation of subspace dimension, to compensate for the potential underestimation of schemes discussed in \cite{nadakuditi2008sample} , a good idea? 

Our performance analysis, which relies on insights from random matrix theory (RMT), highlights the importance of using no more than $\keff$ \textit{informative} signal subspace components, where $\keff$ is a number that depends on the system dimensionality, number of training samples, and eigen-SNR (signal-to-noise-ratio). We derive a new RMT detector that only utilizes the $k_\text{eff}$ \textit{informative} signal subspace components, thereby avoiding some of the possible performance loss suffered by the plug-in detector. Given the number and quality (i.e. SNR) of the training samples, our analysis also allows a practitoner to predict the expected receiver operating characteristic (ROC) performance of a general class of detectors. An outcome of this analyis is that we can accurately predict how many training samples are needed to get to within $\epsilon$ of the oracle MSD's performance (see Figures \ref{fig:epsilon_graph}, \ref{fig:stoch_theory_epsilon}, and \ref{fig:determ_theory_epsilon}). This performance characterization can provide the practitioner with experimental guidance and might be a starting point for the formulation of achievable system performance specifications.

This paper differs from previous works in several aspects. The focus and main contribution is analytically quantifying the performance of a general class of MSD's as a function of the system dimensionality, number of training samples, and eigen-SNR. Theorem \ref{th:other angles} and Corollary \ref{corr:matrix} extend recent results from RMT \cite{paul2007asymptotics,benaych2011eigenvalues, benaych2011singular} to precisely quantify the accuracy of the subspace estimate. This quantification yields approximations that appear to hold for moderate system dimensions even though the theory is asymptotic, in the limit of large dimensionality and relatively large training sample size. We provide a first-principles derivation of a new RMT detector that incorporates this knowledge of the accuracy of the estimated subspace, thereby illuminating the asymptotic form of a detector that mitigates some of the potential performance loss suffered by the plug-in detector. These RMT insights also allow us to characterize the ROC performance of a MSD under both a deterministic and stochastic model for the test vector. This work builds on \cite{asendorf2011msd} by providing the proofs of Theorem \ref{th:other angles} and Corollary \ref{corr:matrix}, analyzing the performance of the general class of detectors given in (\ref{eq:detector_form}), considering the deterministic test vector setting, and unifying the performance analysis of the stochastic and deterministic MSD's.

The paper is organized as follows. We describe the generative models for the training data and test vector and also estimate unknown parameters in Section \ref{sec:data_models}. In Section \ref{sec:std_detecs}, we derive standard oracle and plug-in detectors for each testing setting and highlight how finite training data causes subspace estimation errors and subsequent performance loss. We formally pose the questions addressed herein in Section \ref{sec:prob_state}. Section \ref{sec:rmt} contains pertinent results from RMT and our definition in (\ref{eq:keff}) of $\keff$. In Section \ref{sec:rmt_detecs} we derive RMT detectors for the stochastic and deterministic test vector models. Aided by RMT and a saddlepoint approximation of the CDF of a weighted sum of chi-square random variables, we predict ROC performance curves for a general detector in Section \ref{sec:roc_theory}. We validate our asymptotic ROC predictions and demonstrate the importance of using the $k_\text{eff}$ informative subspace components in Section \ref{sec:results}. We provide concluding remarks in Section \ref{sec:conclusion}.





