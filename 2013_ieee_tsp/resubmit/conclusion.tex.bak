In this paper, we considered a matched subspace detection problem where the low-rank signal subspace is unknown and must be estimated from finite, noisy, signal-bearing training data. We considered both a stochastic and deterministic model for our testing data. The subspace estimate, formed from the eigenvalue decomposition of the sample covariance matrix, is noisy due to finite training samples and noise in the training observation vectors. We used recent results from random matrix theory to precisely quantify the accuracy of the eigenvectors of a sample covariance matrix. An important insight from these results is that only the subspace components whose eigen-SNR is above a certain threshold are informative \cite{nadakuditi2008sample} with predictable bias; the remaining subspace components are uninformative.

Armed with this knowledge, we derived a new RMT detector that only uses the effective number of informative subspace components, $k_\text{eff}$. A detector that uses the uninformative components will thus incur a performance degradation, relative to the RMT detector. However, whenever $\widehat{k}=k_\text{eff}$, the plug-in detector that uses $\widehat{k}$ subspace components will exhibit the same performance as the RMT detector. This highlights the importance of robust techniques \cite{nadakuditi2010fundamental,johnstone2001distribution,el2007tracy} for estimating $k_\text{eff}$ in subspace based detection schemes.

We also used the precise quantification of subspace estimation errors, provided by random matrix theory, to predict the ROC performance of both stochastic and deterministic detectors whose test statistic takes the general form of $\Lambda(w)=w^HDw$. We saw that the conditional distributions of the test statistics can be expressed as a weighted sum of chi-square distributions. The ROC curve can then be computed using a saddlepoint approximation method in the stochastic setting and in closed form in the deterministic setting.

We conclude by noting the interplay between the stochastic and deterministic models considered in (\ref{eq:stoch_setup}) and (\ref{eq:determ_setup}), respectively. Placing a standard normal prior on $x$ in (\ref{eq:determ_setup}) yields the stochastic model in (\ref{eq:stoch_setup}). Hence, we might have computed the ROC performance curve for (\ref{eq:stoch_setup}) by integrating the ROC curve conditioned for the deterministic setting, \textit{conditioned} on a value of $x$. We may thus use this idea to derive the asymptotic ROC performance curve for other non-normal distributions for $x$. In future work, we plan to investigate aspects related to the rate of convergence.

