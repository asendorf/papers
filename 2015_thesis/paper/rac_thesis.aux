\relax 
\@writefile{toc}{\contentsline {chapter}{DEDICATION}{ii}}
\@writefile{toc}{\contentsline {chapter}{ACKNOWLEDGEMENTS}{iii}}
\newlabel{Acknowledgements}{{}{iii}}
\@writefile{toc}{\contentsline {chapter}{LIST OF FIGURES}{v}}
\@writefile{lof}{\noindent \relax $\@@underline {\hbox {\bf  Figure}}\mathsurround \z@ $\relax \hfill \rm  \newline }
\@writefile{toc}{\contentsline {chapter}{ABSTRACT}{vi}}
\newlabel{Abstract}{{}{vii}}
\@writefile{toc}{\mbox { }\newline \noindent {\bf  CHAPTER}\newline }
\@writefile{toc}{\hbox { }}
\citation{melzer2001nonlinear}
\citation{todros2012measure}
\citation{correa2010canonical}
\citation{deleus2011functional}
\citation{hardoon2004canonical}
\citation{ge2009does}
\citation{nielsen2002multiset}
\citation{torres2007finding}
\citation{chaudhuri2009multi}
\citation{hotelling1936relations}
\@writefile{toc}{\hbox { }}
\@writefile{toc}{\contentsline {chap}{\numberline {\hbox { }\hfill \bf  I.\hspace  {5pt}}{\bf  Introduction}}{1}}
\@writefile{toc}{\hbox { }}
\newlabel{sec:intro}{{I}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Multi-Modal Data Fusion}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Illustration of multi-modal data fusion\relax }}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:data_fusion}{{1.1}{1}}
\citation{hardoon2004canonical}
\citation{via2005canonical}
\citation{deleus2011functional}
\citation{correa2010canonical}
\citation{chaudhuri2009multi}
\citation{pezeshki2006canonical}
\citation{gunderson1997estimating}
\citation{pezeshki2004empirical}
\citation{nadakuditi2011fundamental}
\citation{nadakuditi2011fundamental}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Canonical Correlation Analysis (CCA)}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Contributions and Outline}{2}}
\citation{nadakuditi2011fundamental}
\citation{welling2005kcca}
\citation{yu2007learning}
\citation{melzer2001nonlinear}
\citation{kettenring1971canonical}
\citation{nielsen1994analysis}
\citation{pezeshki2004empirical}
\citation{nadakuditi2011fundamental}
\citation{nadakuditi2011fundamental}
\citation{scharf1991statistical}
\citation{friedman2001elements}
\citation{besson2005matched}
\citation{besson2006cfar}
\citation{bandiera2007adaptive}
\citation{bandiera2007glrt}
\citation{maris2003resampling}
\citation{soong1995principal}
\citation{besson2005matched}
\citation{besson2006cfar}
\citation{bandiera2007adaptive}
\citation{bandiera2007glrt}
\citation{scharf1994matched}
\citation{vincent2008matched}
\citation{mcwhorter2003matched}
\citation{jin2005cfar}
\citation{scharf1994matched}
\citation{elden2007matrix}
\citation{hwritingurl}
\citation{elden2007matrix}
\citation{thai2002invariant}
\citation{healey1999models}
\citation{kwon2006kernel}
\@writefile{toc}{\hbox { }}
\@writefile{toc}{\contentsline {chap}{\numberline {\hbox { }\hfill \bf  II.\hspace  {5pt}}{\bf  Performance of Matched Subspace Detectors Using Finite Training Data}}{5}}
\@writefile{toc}{\hbox { }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction}{5}}
\newlabel{sec:ieee_msd_intro}{{2.1}{5}}
\citation{nadakuditi2008sample}
\citation{paul2007asymptotics}
\citation{benaych2011eigenvalues}
\citation{benaych2011singular}
\citation{asendorf2011msd}
\citation{besson2005matched}
\citation{besson2006cfar}
\citation{bandiera2007adaptive}
\citation{bandiera2007glrt}
\citation{maris2003resampling}
\citation{soong1995principal}
\citation{thai2002invariant}
\citation{healey1999models}
\citation{kwon2006kernel}
\citation{healey1999models}
\citation{kwon2006kernel}
\citation{bandiera2007adaptive}
\citation{bandiera2007glrt}
\citation{thai2002invariant}
\citation{healey1999models}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Data Models and Parameter Estimation}{7}}
\newlabel{sec:ieee_msd_data_models}{{2.2}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Training Data Model}{7}}
\newlabel{sec:training_data}{{2.2.1}{7}}
\citation{zhu2006automatic}
\citation{nadakuditi2010fundamental}
\citation{johnstone2001distribution}
\citation{el2007tracy}
\citation{muirhead1982aspects}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Parameter Estimation}{8}}
\newlabel{sec:param_estim}{{2.2.2}{8}}
\newlabel{eq:param_estims_stoch}{{2.1}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Testing Data Model}{8}}
\newlabel{eq:stoch_setup}{{2.2}{8}}
\citation{van1968detection}
\citation{scharf1991statistical}
\newlabel{eq:determ_setup}{{2.3}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Standard Detector Derivations}{9}}
\newlabel{sec:ieee_msd_std_detecs}{{2.3}{9}}
\newlabel{eq:lrt}{{2.4}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Stochastic Testing Model}{9}}
\newlabel{sec:plugin_stoch}{{2.3.1}{9}}
\newlabel{eq:stoch_lrt}{{2.5}{9}}
\newlabel{eq:oracle_stat_stoch_y}{{2.6}{9}}
\newlabel{eq:oracle_stat_stoch_w}{{2.7}{9}}
\citation{mcwhorter2003matched}
\citation{jin2005cfar}
\newlabel{eq:plugin_stat_stoch}{{2.8}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Deterministic Testing Model}{10}}
\newlabel{sec:plugin_determ}{{2.3.2}{10}}
\newlabel{eq:determ_stat_oracle_y}{{2.9}{10}}
\newlabel{eq:determ_stat_oracle_w}{{2.10}{10}}
\citation{scharf1991statistical}
\citation{fawcett2006introduction}
\citation{fawcett2006introduction}
\newlabel{eq:glrt_determ}{{2.11}{11}}
\newlabel{eq:plugin_stat_determ}{{2.12}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Effect of the Number of Training Samples}{11}}
\newlabel{sec:training_effect}{{2.3.3}{11}}
\newlabel{fig:stoch_oracle}{{2.1(a)}{12}}
\newlabel{sub@fig:stoch_oracle}{{(a)}{12}}
\newlabel{fig:determ_oracle}{{2.1(b)}{12}}
\newlabel{sub@fig:determ_oracle}{{(b)}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Empirical ROC curves for the plug-in and oracle detectors. Empirical ROC curves were simulated with $n=200$, $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle k$}\mathaccent "0362{k}=k=2$, and $\Sigma =\mathop {\bf  diag}\left (10,0.1\right )$. The empirical ROC curves were computed using $10000$ test samples and averaged over 100 trials using algorithms 2 and 4 of \cite  {fawcett2006introduction}. (a) Shows results for the stochastic MSD. (b) Shows results for the deterministic MSD when $x=[0.75,0.75]^T$. For both settings, as $m$ decreases, the performance of the plug-in detector degrades.\relax }}{12}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Stochastic Setting}}}{12}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Deterministic Setting}}}{12}}
\newlabel{fig:plugin_v_oracle}{{2.1}{12}}
\newlabel{eq:epsilon}{{2.13}{12}}
\citation{fawcett2006introduction}
\citation{fawcett2006introduction}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Empirically determined number of training samples, $m$, needed for the stochastic plug-in detector to achieve a desired performance loss, $\epsilon $, as defined in (2.13\hbox {}). The required false alarm rate is $P_F=0.1$. Empirical ROC curves were generated for $n=200$, $\Sigma =\mathop {\bf  diag}(10,0.1)$, $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle k$}\mathaccent "0362{k}=k=2$ using 10000 testing samples and averaged over 100 trials using algorithms 2 and 4 of \cite  {fawcett2006introduction}.\relax }}{13}}
\newlabel{fig:epsilon_graph}{{2.2}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Problem Statements}{13}}
\newlabel{sec:ieee_msd_prob_state}{{2.4}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Problem 1: Derive a New Detector that Exploits Predictions of Subspace Accuracy}{13}}
\newlabel{sec:ps_prob2}{{2.4.1}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Problem 2: Characterize ROC Performance Curves}{14}}
\newlabel{sec:problem 1}{{2.4.2}{14}}
\newlabel{eq:detector_form}{{2.14}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Pertinent Results from Random Matrix Theory}{14}}
\newlabel{sec:ieee_msd_rmt}{{2.5}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Eigenvector Aspects}{14}}
\newlabel{sec:eigvect_aspects}{{2.5.1}{14}}
\citation{paul2007asymptotics}
\citation{benaych2011eigenvalues}
\citation{cox1973resolving}
\citation{nadakuditi2008sample}
\citation{nadakuditi2010fundamental}
\citation{nadakuditi2010fundamental}
\citation{nadakuditi2010fundamental}
\citation{johnstone2001distribution}
\citation{el2007tracy}
\newlabel{th:angles}{{2.5.1}{15}}
\newlabel{eq:angles}{{2.15}{15}}
\newlabel{eq:keff}{{2.16}{15}}
\newlabel{th:other angles}{{2.5.1}{15}}
\citation{paul2007asymptotics}
\citation{benaych2011singular}
\newlabel{conj:angles}{{2.5.1}{16}}
\newlabel{corr:matrix}{{2.5.1}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Eigenvalue Aspects}{16}}
\newlabel{th:eigvals_rmt}{{2.5.2}{16}}
\citation{paul2007asymptotics}
\citation{paul2007asymptotics}
\citation{benaych2011singular}
\newlabel{th:eigenvalues}{{2.5.3}{17}}
\newlabel{eq:cov}{{2.17}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Derivation of New RMT Matched Subspace Detectors}{17}}
\newlabel{sec:ieee_msd_rmt_detecs}{{2.6}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Stochastic RMT Detector}{17}}
\newlabel{sec:rmt_stoch}{{2.6.1}{17}}
\citation{nadakuditi2010fundamental}
\newlabel{eq:stoch_distr}{{2.18}{18}}
\newlabel{eq:cov mat}{{2.19}{18}}
\newlabel{eq:optimal_stat_stoch}{{2.20}{18}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Summary of the plug-in and RMT stochastic MSDs. See Sections 2.3.1\hbox {} and 2.6.1\hbox {} for derivations.\relax }}{19}}
\newlabel{table:summary_stoch}{{2.1}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Deterministic RMT Detector}{19}}
\newlabel{sec:rmt_detec_determ}{{2.6.2}{19}}
\newlabel{eq:optimal_stat_determ}{{2.21}{19}}
\citation{fawcett2006introduction}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Summary of the plug-in and RMT deterministic MSDs. See Sections 2.3.2\hbox {} and 2.6.2\hbox {} for derivations.\relax }}{20}}
\newlabel{table:summary_determ}{{2.2}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Theoretical ROC Curve Predictions}{20}}
\newlabel{sec:ieee_msd_roc_theory}{{2.7}{20}}
\newlabel{eq:target cdf}{{2.22}{20}}
\citation{wood1993saddlepoint}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}Stochastic Testing Setting}{21}}
\newlabel{sec:roc_stoch}{{2.7.1}{21}}
\newlabel{eq:stoch_stat_distr}{{2.23}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Deterministic Testing Setting}{21}}
\newlabel{sec:roc_determ}{{2.7.2}{21}}
\newlabel{eq:determ_stat_distr}{{2.24}{21}}
\citation{fawcett2006introduction}
\citation{fawcett2006introduction}
\newlabel{eq:delta}{{2.25}{22}}
\newlabel{eq:roc}{{2.26}{22}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Discussion and Insights}{22}}
\newlabel{sec:ieee_msd_results}{{2.8}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.1}Simulation Protocol}{22}}
\newlabel{sec:sim_proto}{{2.8.1}{22}}
\citation{fawcett2006introduction}
\citation{fawcett2006introduction}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.2}Convergence and Accuracy of ROC Curve Predictions}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.3}Effect of the Number of Training Samples}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.4}Effect of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle k$}\mathaccent "0362{k}$}{25}}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Conclusion}{25}}
\newlabel{sec:ieee_msd_conclusion}{{2.9}{25}}
\citation{nadakuditi2010fundamental}
\citation{johnstone2001distribution}
\citation{el2007tracy}
\citation{benaych2011singular}
\newlabel{eq:eval_master}{{2.27}{26}}
\citation{benaych2011eigenvalues}
\citation{benaych2011eigenvalues}
\newlabel{eq:eval_master2}{{2.28}{27}}
\newlabel{eq:t_trans}{{2.29}{27}}
\newlabel{eq:Mn}{{2.30}{27}}
\citation{silverstein1985smallest}
\citation{barvinok2005measure}
\newlabel{fig:stoch_n_effect1}{{2.3(a)}{29}}
\newlabel{sub@fig:stoch_n_effect1}{{(a)}{29}}
\newlabel{fig:stoch_n_effect4}{{2.3(b)}{29}}
\newlabel{sub@fig:stoch_n_effect4}{{(b)}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Empirical and theoretical ROC curves for the stochastic plug-in detector. Empirical ROC curves were simulated using $10000$ test samples and averaged over 50 trials using algorithms 2 and 4 of \cite  {fawcett2006introduction}. (a) $\Sigma =\mathop {\bf  diag}(10,2)$, $c=1$, $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle k$}\mathaccent "0362{k}=k=2$ so that $k_\text  {eff}=2$. (b) $\Sigma =\mathop {\bf  diag}(10,2,0.5,0.1)$, $c=10$, $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle k$}\mathaccent "0362{k}=k=4$ so that $k_\text  {eff}=1$. Each figure plots empirical ROC curves for $n=50,200,1000$. Theoretical ROC curves were computed as described in Section \G@refundefinedtrue \text  {\normalfont  \bfseries  ??}\GenericWarning  {               }{LaTeX Warning: Reference `sec:roc_theory' on page 29 undefined}. As $n$ increases, the empirical ROC curves approach the theoretically predicted one. However, this convergence is slower for larger $k$ and $c$.\relax }}{29}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$k=2$, $c=1$}}}{29}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$k=4$, $c=10$}}}{29}}
\newlabel{fig:stoch_roc_pred}{{2.4(a)}{30}}
\newlabel{sub@fig:stoch_roc_pred}{{(a)}{30}}
\newlabel{fig:determ_roc_pred}{{2.4(b)}{30}}
\newlabel{sub@fig:determ_roc_pred}{{(b)}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Empirical and theoretical ROC curves for the plug-in and RMT detectors. Empirical ROC curves were simulated using $10000$ test vectors and averaged over 100 trials with $n=1000$, $m=500$, and $\Sigma =\alpha \mathop {\bf  diag}\left (10,5\right )$. The theoretical ROC curves were computed as described in Section \G@refundefinedtrue \text  {\normalfont  \bfseries  ??}\GenericWarning  {               }{LaTeX Warning: Reference `sec:roc_theory' on page 30 undefined}. (a) Stochastic testing setting. Results are plotted for $\alpha =1,0.5,0.25$. For $\alpha =1$ and $\alpha =0.5$, $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle k$}\mathaccent "0362{k}=k=k_\text  {eff}=2$ by (3.16\hbox {}). For $\alpha =0.25$, $k_\text  {eff}=1$.Since $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle k$}\mathaccent "0362{k} > k_{\text  {eff}}$ when $\alpha =0.25$, we observe a performance gain when using the RMT detector. (b) Deterministic testing setting. Results are plotted for $\alpha =1$ so that $k_\text  {eff}=2$. Three values of the deterministic signal vector were used: $x=[1,1]^T$, $x=[0.5,0.5]^T$, and $x=[0.25,0.25]^T$. The resulting ROC curves depend on the choice of $x$, however, since $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle k$}\mathaccent "0362{k} = k_{\text  {eff}}$, the plug-in and RMT detector achieve the same performance for all $x$. For both the stochastic and deterministic detectors, the theoretically predicted ROC curves match the empirical ROC curves, reflecting the accuracy of Corollary 2.5.1\hbox {} and the Lugannani-Rice formula.\relax }}{30}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Stochastic}}}{30}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Deterministic}}}{30}}
\newlabel{fig:stoch_m_large}{{2.5(a)}{31}}
\newlabel{sub@fig:stoch_m_large}{{(a)}{31}}
\newlabel{fig:stoch_m_small}{{2.5(b)}{31}}
\newlabel{sub@fig:stoch_m_small}{{(b)}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Empirical and theoretical ROC curves for the plug-in and RMT stochastic detectors. Empirical ROC curves were computed with 10000 test samples and averaged over 100 trials. Here, $n=5000$, $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle k$}\mathaccent "0362{k}=k=4$ and $\Sigma = \mathop {\bf  diag}({\bf  {10,3,2.5,2}})$. The empirical oracle ROC curve is provided for relative comparison purposes. (a) $m=5000$ so that $c=1$ and $k_\text  {eff}=\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle k$}\mathaccent "0362{k}=4$. The plug-in and RMT detectors achieve relatively the same performance. (b) $m=250$ so that $c=20$ and $k_\text  {eff}=1<\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle k$}\mathaccent "0362{k}=4$. The RMT detector avoids some of the performance loss realized by the plug-in detector. As seen in Section \G@refundefinedtrue \text  {\normalfont  \bfseries  ??}\GenericWarning  {               }{LaTeX Warning: Reference `sec:std_detecs' on page 31 undefined}, limited training samples degrades detector performance. However, the new RMT detector does not suffer as badly as the plug-in detector because it accounts for subspace estimation errors due to finite training data. The disagreement between the theoretical and empirical ROC curves is attributed to finite dimensionality.\relax }}{31}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$m=5000$}}}{31}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$m=250$}}}{31}}
\newlabel{fig:stoch_m_effect}{{2.5}{31}}
\newlabel{fig:stoch_theory_epsilon}{{2.6(a)}{32}}
\newlabel{sub@fig:stoch_theory_epsilon}{{(a)}{32}}
\newlabel{fig:determ_theory_epsilon}{{2.6(b)}{32}}
\newlabel{sub@fig:determ_theory_epsilon}{{(b)}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Theoretically determined number of training samples, $m$, needed to achieve a desired performance loss, $\epsilon $, as defined in (2.13\hbox {}). The required false alarm rate is $P_F=0.1$ with $n=200$, $\Sigma = \mathop {\bf  diag}(10,0.1)$, and $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle k$}\mathaccent "0362{k}=k=2$. (a) Results for the stochastic detectors. We see that for a given $\epsilon $, the new RMT detector requires less training samples. (b) Results for the deterministic detectors when $x=[0.75,0.75]^T$. Again, for a given $\epsilon $, the new RMT detector requires less training samples. In the deterministic setting, the limiting performance loss is different (and non-zero) for the plug-in and RMT detectors. This arises in estimation errors of $x$ in the GLRT.\relax }}{32}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Stochastic}}}{32}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Deterministic}}}{32}}
\newlabel{fig:epsilon_combined}{{2.6}{32}}
\newlabel{fig:stoch_khat}{{\caption@xref {fig:stoch_khat}{ on input line 123}}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Empirical exploration of the achieved probability of detection, $P_D$, for a fixed probability of false alarm, $P_F=0.01$, for various $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle k$}\mathaccent "0362{k}$. Empirical ROC curves were computed using 10000 test samples and averaged over 100 trials with $n=1000$, $m=500$, and $\Sigma = \mathop {\bf  diag}({\bf  {10,5,4}},0.75,0.5,0.25)$ so that $k_{\text  {eff}}=3$. Results for the stochastic detectors. The optimal $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle k$}\mathaccent "0362{k}$ resulting in the largest $P_D$ is not the true $k$, but rather $k_\text  {eff}$.\relax }}{33}}
\newlabel{fig:khat_graphs}{{2.7}{33}}
\citation{cui2013performance}
\citation{arribas2013antenna}
\citation{gorji2013widely}
\citation{zhou2013space}
\citation{cui2013performance}
\citation{santiago2013noise}
\citation{hu2013doa}
\citation{liao2013direction}
\citation{arribas2013antenna}
\citation{chen2013adaptive}
\citation{gorji2013widely}
\citation{zhou2013space}
\citation{kwon2013multi}
\citation{besson2005matched}
\citation{bandiera2007glrt}
\citation{bandiera2007adaptive}
\citation{sirianunpiboon2013multiple}
\citation{vazquez2011spatial}
\citation{scharf1994matched}
\citation{vincent2008matched}
\citation{besson2006cfar}
\citation{asendorf2013performance}
\@writefile{toc}{\hbox { }}
\@writefile{toc}{\contentsline {chap}{\numberline {\hbox { }\hfill \bf  III.\hspace  {5pt}}{\bf  Useful Subspace Components in Deterministic Matched Subspace Detectors}}{34}}
\@writefile{toc}{\hbox { }}
\newlabel{sec:taes_useful}{{III}{34}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction}{34}}
\newlabel{sec:intro}{{3.1}{34}}
\newlabel{eq:general_setup}{{3.1}{34}}
\citation{asendorf2013performance}
\citation{cui2013performance}
\citation{santiago2013noise}
\citation{arribas2013antenna}
\citation{chen2013adaptive}
\citation{gorji2013widely}
\citation{zhou2013space}
\citation{kwon2013multi}
\citation{hu2013doa}
\citation{liao2013direction}
\citation{van1968detection}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Problem Formulation}{35}}
\newlabel{sec:energy_detector}{{3.2}{35}}
\newlabel{eq:lrt_form}{{3.2}{35}}
\citation{cui2013performance}
\citation{arribas2013antenna}
\citation{zhou2013space}
\newlabel{eq:energy_detector}{{3.3}{36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}ROC Curve Analysis}{36}}
\newlabel{eq:roc}{{3.4}{36}}
\newlabel{eq:distr_energy}{{3.5}{36}}
\newlabel{eq:roc_energy}{{3.6}{37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Problem Statement}{37}}
\newlabel{sec:prob_state}{{3.2.2}{37}}
\newlabel{eq:the_detector}{{3.7}{37}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Useful Components In Energy Detectors}{37}}
\newlabel{sec:useful}{{3.3}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Algorithm to determine $k_{\text  {useful}}$. This is computable in an oracle setting where $\delta $ is known.\relax }}{38}}
\newlabel{algo:kuse}{{3.1}{38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Definition and Computation of $k_{\text  {useful}}$}{38}}
\newlabel{eq:opt_prob}{{3.8}{38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Discussion of Test Statistic Distributions}{38}}
\newlabel{eq:d_distrs}{{3.9}{38}}
\newlabel{eq:nc_param}{{3.10}{39}}
\newlabel{eq:simple_opt}{{3.11}{39}}
\citation{asendorf2013performance}
\newlabel{fig:small}{{3.2(a)}{40}}
\newlabel{sub@fig:small}{{(a)}{40}}
\newlabel{fig:med}{{3.2(b)}{40}}
\newlabel{sub@fig:med}{{(b)}{40}}
\newlabel{fig:big}{{3.2(c)}{40}}
\newlabel{sub@fig:big}{{(c)}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Probability density function (p.d.f.) of $\Lambda (w)\tmspace  +\thinmuskip {.1667em}|\tmspace  +\thinmuskip {.1667em}H_0$ and $\Lambda (w)\tmspace  +\thinmuskip {.1667em}|\tmspace  +\thinmuskip {.1667em}H_1$ for three combinations of the number of components $d$ and non-centrality parameter $\lambda _d$. (a) Baseline: $d=1$, $\lambda _d=2$ (b) Increases $d$ but keeps $\lambda _d$ fixed. The distributions are less separable. (c) Increases both $d$ and $\lambda _d$. The distributions are more separable.\relax }}{40}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$d=1$, $\lambda _d=2$}}}{40}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$d=2$, $\lambda _d=2$}}}{40}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {$d=2$, $\lambda _d=3$}}}{40}}
\newlabel{fig:distributions}{{3.2}{40}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Application to Deterministic Matched Subspace Detectors}{40}}
\newlabel{sec:msd}{{3.4}{40}}
\citation{chen2013adaptive}
\citation{arribas2013antenna}
\citation{he2013near}
\citation{liao2013direction}
\citation{kwon2013multi}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The corresponding ROC curves to the three choices of $d$ and $\lambda _d$ in Figure 3.2\hbox {}. ROC curves were generated from (3.4\hbox {}). When adding an additional subspace component, the non-centrality parameter must increase sufficiently in order to achieve improved detection. \relax }}{41}}
\newlabel{fig:dist_roc}{{3.3}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Training Data Model}{41}}
\newlabel{sec:training_data}{{3.4.1}{41}}
\citation{muirhead1982aspects}
\citation{asendorf2013performance}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Minimum increase in non-centrality parameter necessary for increased detector performance. Results are shown for multiple choices of $P_F$. $\lambda _1$ indicates the non-centrality parameter when $d=1$ and $\Delta \lambda $ indicates the increase in non-centrality parameter when increasing the number of components to $d=2$.\relax }}{42}}
\newlabel{fig:nc_lines}{{3.4}{42}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Testing Data Model}{42}}
\newlabel{eq:determ_setup}{{3.13}{42}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Subspace Estimation and Accuracy}{42}}
\newlabel{sec:param_estim}{{3.4.3}{42}}
\newlabel{eq:param_estims_stoch}{{3.14}{42}}
\citation{asendorf2013performance}
\citation{nadakuditi2008sample}
\citation{scharf1994matched}
\citation{vincent2008matched}
\citation{fuchs2007robust}
\citation{asendorf2013performance}
\citation{santiago2013noise}
\citation{arribas2013antenna}
\citation{asendorf2013performance}
\citation{asendorf2013performance}
\newlabel{eq:angles}{{3.15}{43}}
\newlabel{eq:keff}{{3.16}{43}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Plug-in and RMT Detectors}{43}}
\newlabel{eq:plugin_stat}{{3.17}{43}}
\newlabel{eq:rmt_stat}{{3.18}{43}}
\newlabel{eq:msd_nc_param}{{3.19}{43}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.5}Relationship between $k_{\text  {useful}}$ and $k_\text  {eff}$}{44}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.6}Numerical Example}{45}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Extension - Weighted Energy Detector}{45}}
\newlabel{sec:ext}{{3.5}{45}}
\newlabel{eq:weighted_detector}{{3.20}{45}}
\newlabel{eq:roc_weighted}{{3.21}{45}}
\citation{wood1993saddlepoint}
\citation{fawcett2006introduction}
\newlabel{eq:weighted_pd}{{3.22}{46}}
\citation{asendorf2013performance}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Conclusion}{47}}
\newlabel{sec:conclusion}{{3.6}{47}}
\newlabel{fig:det_perf}{{3.5(a)}{48}}
\newlabel{sub@fig:det_perf}{{(a)}{48}}
\newlabel{fig:dvals}{{3.5(b)}{48}}
\newlabel{sub@fig:dvals}{{(b)}{48}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Deterministic energy detector performance as a function of the number of training samples. In this experiment $n=200$, $\Sigma =\mathop {\bf  diag}(5,2,0.5)$, $x=[1.5,1.5,1.5]^T$, and the required false alarm rate is $P_F=0.1$. (a) The theoretical probability of detection achieved by the plug-in, RMT, and useful detectors. $P_D(P_F)$ is calculated in (3.4\hbox {}). The plug-in detector sets $d=k$, the RMT detector sets $k=k_\text  {eff}$ as defined in (3.16\hbox {}), and the useful detector sets $d=k_{\text  {useful}}$ as calculated in Figure 3.1\hbox {} using the non-centrality parameter defined in (3.19\hbox {}). The useful detector achieves the optimal performance. (b) The number of subspace components used by the plug-in, RMT, and useful detectors. Whenever $k_\text  {eff}\not =k_{\text  {useful}}$, the RMT detector realizes a suboptimal detector performance. Even though these subspace components are \textit  {informative}, there is not enough training data to make them \textit  {useful} in detection.\relax }}{48}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Detector Performance}}}{48}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Number of Subspace Components}}}{48}}
\newlabel{fig:main_result}{{3.5}{48}}
\newlabel{fig:weights_easy}{{3.6(a)}{49}}
\newlabel{sub@fig:weights_easy}{{(a)}{49}}
\newlabel{fig:weights_hard}{{3.6(b)}{49}}
\newlabel{sub@fig:weights_hard}{{(b)}{49}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Empirically achieved probability of detection ($P_D$) as a function of the weighting coefficient $a$ for a fixed false alarm rate of $P_F=0.1$. (a) Two detectors, one using the deterministic vector $\delta =[1,1]^T$ and the second using $\delta =[1,0]^T$. The first detector achieves its maximum performance around $a=0.5$ indicating that both components are equally informative. The second detector achieves its maximum performance at $a=1$ indicating the second subspace component is not useful in detection. (b) Two detectors, one using $\delta =[1, 0.75]^T$ and the other using $\delta =[1, 0.5]^T$. The maximum performance of each detector is no longer achieved at $a=0.5$ or $a=1$ as the entries of $\delta $ are non-zero and are not equal. The maximum performance is indicated by a black circle.\relax }}{49}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Easy Optimal Weights}}}{49}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Difficult Optimal Weights}}}{49}}
\newlabel{fig:weighted}{{3.6}{49}}
\citation{pezeshki2004empirical}
\citation{nadakuditi2011fundamental}
\citation{nadakuditi2011fundamental}
\@writefile{toc}{\hbox { }}
\@writefile{toc}{\contentsline {chap}{\numberline {\hbox { }\hfill \bf  IV.\hspace  {5pt}}{\bf  Background: Canonical Correlation Analysis (CCA)}}{50}}
\@writefile{toc}{\hbox { }}
\newlabel{sec:cca}{{IV}{50}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Mathematical Formulation of CCA}{50}}
\newlabel{sec:cca_form}{{4.1}{50}}
\newlabel{eq:cca_opt}{{4.1}{50}}
\newlabel{eq:cca_opt2}{{4.2}{50}}
\newlabel{eq:cca_lagr}{{4.3}{50}}
\citation{nielsen2002multiset}
\citation{nadakuditi2011fundamental}
\citation{welling2005kcca}
\citation{kettenring1971canonical}
\citation{nielsen1994analysis}
\newlabel{eq:cca_partials}{{4.4}{51}}
\newlabel{eq:cca_rho}{{4.5}{51}}
\newlabel{eq:cca_eigval_sys}{{4.6}{51}}
\newlabel{eq:x2}{{4.7}{51}}
\newlabel{eq:eigval_sys2}{{4.8}{51}}
\newlabel{eq:cca_C_eigval}{{4.9}{51}}
\newlabel{eq:cca_svd_sol}{{4.10}{51}}
\citation{pezeshki2004empirical}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Empirical CCA}{52}}
\newlabel{sec:emp_cca}{{4.2}{52}}
\newlabel{eq:scm}{{4.11}{52}}
\newlabel{eq:cca_Chat}{{4.12}{52}}
\newlabel{eq:cca_svd_sol}{{4.13}{52}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Performance of Empirical CCA}{52}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Performance Breakdown When $n<d_1+d_2$}{52}}
\newlabel{eq:cca_chat_svd}{{4.14}{53}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Simulation Results}{53}}
\newlabel{eq:cca_data_model1}{{4.15}{53}}
\citation{pezeshki2004empirical}
\citation{nadakuditi2011fundamental}
\citation{nadakuditi2011fundamental}
\newlabel{fig:cca_errorbars_low_snr}{{4.1(a)}{55}}
\newlabel{sub@fig:cca_errorbars_low_snr}{{(a)}{55}}
\newlabel{fig:cca_errorbars_high_snr}{{4.1(b)}{55}}
\newlabel{sub@fig:cca_errorbars_high_snr}{{(b)}{55}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Empirical distribution of the top singular value of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle C$}\mathaccent "0362{C}$ in (4.14\hbox {}) for both noise and signal data models in (4.15\hbox {}). Simulations were conducted using $d_1=200$, $d_2=150$, and $\rho =0.9$. The top singular value was computed for 500 trials. The mean top singular value is plotted with $\pm $ one standard deviation errorbars. \relax }}{55}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$\sigma =0$ dB}}}{55}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$\sigma =3$ dB}}}{55}}
\newlabel{fig:cca_errorbars}{{4.1}{55}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Two-sided KS statistic between the empirical distributions of the leading singular value of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle C$}\mathaccent "0362{C}$ in (4.14\hbox {}) formed from training data generated from the noise and signal data models in (4.15\hbox {}). Simulations were conducted using $d_1=200$, $d_2=150$, $\rho =0.9$, 500 trials, and a significance level of $\alpha =0.95$ for the KS test. A value of 1 indicates the distributions are statistically different while a value of 0 indicates the distributions are statistically identical.\relax }}{56}}
\newlabel{fig:cca_ks_heatmap}{{4.2}{56}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces AUC for a detector based on the top singular value of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle C$}\mathaccent "0362{C}$ in (4.14\hbox {}) to detect the noise and signal data models in (4.15\hbox {}). Simulations were conducted using $d_1=200$, $d_2=150$, 500 trials, and $\rho =0.9$.\relax }}{56}}
\newlabel{fig:cca_auc_heatmap}{{4.3}{56}}
\citation{nadakuditi2011fundamental}
\citation{nadakuditi2011fundamental}
\citation{nadakuditi2011fundamental}
\citation{nadakuditi2011fundamental}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Informative CCA (ICCA)}{57}}
\newlabel{prop:raj}{{4.4.1}{57}}
\newlabel{eq:icca_chat}{{4.16}{57}}
\newlabel{eq:icca_rho}{{4.17}{57}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Simulation results}{58}}
\newlabel{fig:icca_errorbars_low_snr}{{4.4(a)}{58}}
\newlabel{sub@fig:icca_errorbars_low_snr}{{(a)}{58}}
\newlabel{fig:icca_errorbars_high_snf}{{4.4(b)}{58}}
\newlabel{sub@fig:icca_errorbars_high_snf}{{(b)}{58}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Empirical distribution of the top singular value of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle C$}\mathaccent "0365{C}$ in (4.16\hbox {}) for both noise and signal data models in (4.15\hbox {}). Simulations were conducted using $d_1=200$, $d_2=150$, $\rho =0.9$, and $r_1=r_2=1$. The top singular value was computed for 500 trials. The mean top singular value is plotted with $\pm $ one standard deviation errorbars.\relax }}{58}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$\sigma =0$ dB}}}{58}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$\sigma =3$ dB}}}{58}}
\newlabel{fig:icca_errorbars}{{4.4}{58}}
\citation{nadakuditi2011fundamental}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Two-sided KS statistic between the empirical distributions of the leading singular value of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle C$}\mathaccent "0365{C}$ in (4.16\hbox {}) formed from training data generated from the noise and signal data models in (4.15\hbox {}). Simulations were conducted using $d_1=200$, $d_2=150$, $\rho =0.9$, $r_1=r_2=1$, 500 trials, and a significance level of $\alpha =0.95$ for the KS test. A value of 1 indicates the distributions are statistically different while a value of 0 indicates the distributions are statistically identical.\relax }}{59}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {CCA}}}{59}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {ICCA}}}{59}}
\newlabel{fig:icca_ks_heatmap}{{4.5}{59}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces AUC for a detector based on the top singular value of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle C$}\mathaccent "0365{C}$ in (4.16\hbox {}) to detect the noise and signal data models in (4.15\hbox {}). Simulations were conducted using $d_1=200$, $d_2=150$, $\rho =0.9$, 500 trials, and $r_1=r_2=1$.\relax }}{60}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {CCA}}}{60}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {ICCA}}}{60}}
\newlabel{fig:icca_auc_heatmap}{{4.6}{60}}
\citation{besson2006cfar}
\citation{besson2005matched}
\citation{bandiera2007glrt}
\citation{bandiera2007adaptive}
\citation{elden2007matrix}
\citation{mcwhorter2003matched}
\citation{vincent2008matched}
\citation{scharf1994matched}
\citation{jin2005cfar}
\citation{asendorf2013performance}
\citation{asendorf2012performance}
\citation{pezeshki2006canonical}
\@writefile{toc}{\hbox { }}
\@writefile{toc}{\contentsline {chap}{\numberline {\hbox { }\hfill \bf  V.\hspace  {5pt}}{\bf  Low-Rank Gauss-Gauss Detection with Two Datasets}}{61}}
\@writefile{toc}{\hbox { }}
\newlabel{sec:cca_detec}{{V}{61}}
\citation{van1968detection}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Data Model}{62}}
\newlabel{eq:cca_detect_model}{{5.1}{62}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}LRT Detector Derivation}{62}}
\newlabel{eq:lrt}{{5.2}{62}}
\newlabel{eq:lrt_stat}{{5.3}{63}}
\newlabel{eq:lrt_detect}{{5.4}{63}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}CCA Detector Equivalency}{63}}
\newlabel{eq:cca_stat}{{5.5}{65}}
\newlabel{eq:cca_detect}{{5.6}{65}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}CCA Detector for Data Model (5.1\hbox {})}{65}}
\newlabel{eq:cca_detec_C}{{5.7}{65}}
\newlabel{eq:cca_stat_r}{{5.8}{66}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Empirical Detectors}{66}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Parameter Estimation}{66}}
\newlabel{sec:param_estims}{{5.4.1}{66}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Rank-1 Detectors}{67}}
\newlabel{eq:plugin_lrt_stat}{{5.9}{67}}
\newlabel{eq:emp_cca_detec_params}{{5.10}{67}}
\newlabel{eq:cca_plugin_stat}{{5.11}{67}}
\newlabel{eq:icca_plugin_stat}{{5.12}{68}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Rank 1 Proof that $\Lambda _{\text  {icca}}(\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle w$}\mathaccent "0365{w}_{r^*}) \equiv \Lambda _{\text  {plug-in}}(y)$}{68}}
\citation{fawcett2006introduction}
\citation{fawcett2006introduction}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Rank 1 Numerical Simulations}{69}}
\citation{fawcett2006introduction}
\citation{fawcett2006introduction}
\citation{fawcett2006introduction}
\citation{fawcett2006introduction}
\newlabel{fig:auc_lrt_high_rho}{{5.1(a)}{71}}
\newlabel{sub@fig:auc_lrt_high_rho}{{(a)}{71}}
\newlabel{fig:auc_icca_high_rho}{{5.1(b)}{71}}
\newlabel{sub@fig:auc_icca_high_rho}{{(b)}{71}}
\newlabel{fig:auc_cca_high_rho}{{5.1(c)}{71}}
\newlabel{sub@fig:auc_cca_high_rho}{{(c)}{71}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces AUC results for the plug-in LRT, empirical CCA, and ICCA detectors in (5.9\hbox {}), (5.11\hbox {}), and (5.12\hbox {}), respectively. Empirical ROC curves were simulated using $2000$ test samples for each hypothesis and averaged over $50$ trials using algorithms 2 and 4 of \cite  {fawcett2006introduction}. Simulations parameters were $d_1=200$, $d_2=150$, and $\rho =0.8$. Each figure plots the AUC for the average ROC curve at a different values of SNR, $\sigma =\sigma _1=\sigma _2$, and training samples, $n$.\relax }}{71}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Plug-in LRT}}}{71}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {ICCA}}}{71}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Empirical CCA}}}{71}}
\newlabel{fig:auc_high_rho}{{5.1}{71}}
\newlabel{fig:auc_lrt_low_rho}{{5.2(a)}{72}}
\newlabel{sub@fig:auc_lrt_low_rho}{{(a)}{72}}
\newlabel{fig:auc_icca_low_rho}{{5.2(b)}{72}}
\newlabel{sub@fig:auc_icca_low_rho}{{(b)}{72}}
\newlabel{fig:auc_cca_low_rho}{{5.2(c)}{72}}
\newlabel{sub@fig:auc_cca_low_rho}{{(c)}{72}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces AUC results for the plug-in LRT, empirical CCA, and ICCA detectors in (5.9\hbox {}), (5.11\hbox {}), and (5.12\hbox {}), respectively. Empirical ROC curves were simulated using $2000$ test samples for each hypothesis and averaged over $50$ trials using algorithms 2 and 4 of \cite  {fawcett2006introduction}. Simulations parameters were $d_1=200$, $d_2=150$, and $\rho =0.2$. Each figure plots the AUC for the average ROC curve at a different value of SNR, $\sigma =\sigma _1=\sigma _2$, and training samples, $n$.\relax }}{72}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Plug-in LRT}}}{72}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {ICCA}}}{72}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {CCA}}}{72}}
\newlabel{fig:auc_low_rho}{{5.2}{72}}
\@writefile{toc}{\hbox { }}
\@writefile{toc}{\contentsline {chap}{\numberline {\hbox { }\hfill \bf  VI.\hspace  {5pt}}{\bf  Regularized CCA (RCCA)}}{74}}
\@writefile{toc}{\hbox { }}
\newlabel{sec:rcca}{{VI}{74}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Mathematical Formulation of RCCA}{74}}
\newlabel{eq:rcca_opt1}{{6.1}{74}}
\newlabel{eq:rcca_opt2}{{6.2}{75}}
\newlabel{eq:rcca_opt}{{6.3}{75}}
\newlabel{eq:rcca_partials}{{6.4}{75}}
\newlabel{eq:rcca_x2}{{6.5}{75}}
\newlabel{eq:rcca_eigval}{{6.6}{75}}
\newlabel{eq:rcca_svd}{{6.7}{76}}
\newlabel{eq:rcca_sol}{{6.8}{76}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Empirical RCCA}{76}}
\newlabel{eq:creghat}{{6.9}{76}}
\newlabel{eq:emp_rcca_sol}{{6.10}{76}}
\newlabel{eq:rcca_chat_decomp}{{6.11}{77}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Performance of Empirical RCCA}{77}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Simulation Setup}{77}}
\newlabel{sec:rcca_sim_setup}{{6.3.1}{77}}
\newlabel{eq:rcca_data_model1}{{6.12}{77}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Distribution of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \rho $}\mathaccent "0362{\rho }$}{78}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.3}Detection Based on $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \rho $}\mathaccent "0362{\rho }$}{78}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Empirical distribution of the top singular value of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle C$}\mathaccent "0362{C}_{\text  {reg}}$ in (6.9\hbox {}) for both noise and signal data models in (6.12\hbox {}). Simulations were conducted using $d_1=200$, $d_2=150$, $\rho =0.9$, and $\sigma =0$ dB. Results are shown for four values of $n$. The top singular value was computed for 500 trials. The mean top singular value is plotted with $\pm $ one standard deviation errorbars. The distribution of the top singular value of the noise distribution is plotted in green and that of the signal distribution is plotted in black.\relax }}{79}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$n=50$}}}{79}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$n=150$}}}{79}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {$n=300$}}}{79}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {$n=600$}}}{79}}
\newlabel{fig:rcca_errorbars_low_snr}{{6.1}{79}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Empirical distribution of the top singular value of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle C$}\mathaccent "0362{C}_{\text  {reg}}$ in (6.9\hbox {}) for both noise and signal data models in (6.12\hbox {}). Simulations were conducted using $d_1=200$, $d_2=150$, $\rho =0.9$, and $\sigma =3$ dB. Results are shown for four values of $n$. The top singular value was computed for 500 trials. The mean top singular value is plotted with $\pm $ one standard deviation errorbars. The distribution of the top singular value of the noise distribution is plotted in green and that of the signal distribution is plotted in black.\relax }}{80}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$n=50$}}}{80}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$n=150$}}}{80}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {$n=300$}}}{80}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {$n=600$}}}{80}}
\newlabel{fig:rcca_errorbars_high_snr}{{6.2}{80}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Empirical AUC of the detector based on the top singular value of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle C$}\mathaccent "0362{C}_{\text  {reg}}$ in (6.9\hbox {}) based on the data models in (6.12\hbox {}). Simulations were conducted using $d_1=200$, $d_2=150$, $\rho =0.9$, and 500 trials. Results are shown for 4 values of $n$. In each figure, the AUC is plotted for multiple combinations of $\sigma $ and $\eta $.\relax }}{81}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$n=50$}}}{81}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$n=150$}}}{81}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {$n=300$}}}{81}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {$n=600$}}}{81}}
\newlabel{fig:rcca_auc_heatmap}{{6.3}{81}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Informative RCCA (IRCCA)}{82}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}IRCCA Derivation}{82}}
\newlabel{eq:rcca_rhohat}{{6.13}{82}}
\newlabel{eq:cregtil}{{6.14}{82}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.2}Numerical Simulations}{83}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Empirical distribution of the top singular value of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle C$}\mathaccent "0365{C}_{\text  {reg}}$ in (6.14\hbox {}) for both noise and signal data models in (6.12\hbox {}). Simulations were conducted using $d_1=200$, $d_2=150$, $\rho =0.9$, and $\sigma =0$ dB. Results are shown for four values of $n$. The top singular value was computed for 500 trials. The mean top singular value is plotted with $\pm $ one standard deviation errorbars. The figure plots the distribution of the top singular value of the RCCA noise distribution (green), RCCA signal distribution (black), IRCCA noise distribution (blue), and IRCCA signal distribution (red).\relax }}{84}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$n=50$}}}{84}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$n=150$}}}{84}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {$n=300$}}}{84}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {$n=600$}}}{84}}
\newlabel{fig:rcca_errorbars_low_snr}{{6.4}{84}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Empirical distribution of the top singular value of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle C$}\mathaccent "0362{C}_{\text  {reg}}$ in (6.9\hbox {}) for both noise and signal data models in (6.12\hbox {}). Simulations were conducted using $d_1=200$, $d_2=150$, $\rho =0.9$, and $\sigma =3$ dB. Results are shown for four values of $n$. The top singular value was computed for 500 trials. The mean top singular value is plotted with $\pm $ one standard deviation errorbars. The figures plots the distribution of the top singular value of the RCCA noise distribution (green), RCCA signal distribution (black), IRCCA noise distribution (blue), and IRCCA signal distribution (red).\relax }}{85}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$n=50$}}}{85}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$n=150$}}}{85}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {$n=300$}}}{85}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {$n=600$}}}{85}}
\newlabel{fig:rcca_errorbars_high_snr}{{6.5}{85}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces Empirical AUC of the detector based on the top singular value of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle C$}\mathaccent "0365{C}_{\text  {reg}}$ in (6.9\hbox {}) based on the data models in (6.12\hbox {}). Simulations were conducted using $d_1=200$, $d_2=150$, $\rho =0.9$, and 500 trials. Results are shown for IRCCA and the difference between IRCCA and RCCA for $n=50,150$. In each figure, the AUC is plotted for multiple combinations of $\sigma $ and $\eta $. In the difference plots, positive values indicate that IRCCA does better and negative values indicate that RCCA does better.\relax }}{86}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {IRCCA, $n=50$}}}{86}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {RCCA Difference, $n=50$}}}{86}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {IRCCA, $n=150$}}}{86}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {RCCA Difference, $n=150$}}}{86}}
\newlabel{fig:ircca_auc_heatmap1}{{6.6}{86}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces Empirical AUC of the detector based on the top singular value of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle C$}\mathaccent "0365{C}_{\text  {reg}}$ in (6.9\hbox {}) based on the data models in (6.12\hbox {}). Simulations were conducted using $d_1=200$, $d_2=150$, $\rho =0.9$, and 500 trials. Results are shown for IRCCA and the difference between IRCCA and RCCA for $n=300,600$. In each figure, the AUC is plotted for multiple combinations of $\sigma $ and $\eta $. In the difference plots, positive values indicate that IRCCA does better and negative values indicate that RCCA does better.\relax }}{87}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {IRCCA, $n=300$}}}{87}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {RCCA Difference, $n=300$}}}{87}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {IRCCA, $n=600$}}}{87}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {RCCA Difference, $n=600$}}}{87}}
\newlabel{fig:ircca_auc_heatmap2}{{6.7}{87}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Limiting as $\eta \to \infty $}{87}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Conclusion}{88}}
\citation{rao2008polynomial}
\@writefile{toc}{\hbox { }}
\@writefile{toc}{\contentsline {chap}{\numberline {\hbox { }\hfill \bf  VII.\hspace  {5pt}}{\bf  Significance Tests}}{90}}
\@writefile{toc}{\hbox { }}
\newlabel{sec:sig_tests}{{VII}{90}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Distribution of CCA Correlations}{91}}
\citation{pezeshki2004empirical}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces RMTool {\sc  {Matlab}} code for CCA eigenvalue distribution assuming that $d_2>d_1$\relax }}{92}}
\newlabel{fig:cca_rmtool}{{7.1}{92}}
\newlabel{eq:cca_st}{{7.5}{92}}
\newlabel{eq:cca_z}{{7.7}{92}}
\citation{johnstone2008multivariate}
\citation{johnstone2008multivariate}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Distribution of Largest CCA Correlation}{93}}
\newlabel{eq:mu_sigma}{{7.12}{93}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Significance test for CCA\relax }}{94}}
\newlabel{algo:cca_sig}{{7.2}{94}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Distribution of ICCA Correlations}{94}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Distribution of RCCA Correlations}{94}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces RMTool {\sc  {Matlab}} code for RCCA eigenvalue distribution assuming that $d_2>d_1$\relax }}{95}}
\newlabel{fig:rcca_rmtool}{{7.3}{95}}
\citation{akaho2006kernel}
\citation{melzer2001kernel}
\citation{melzer2001kernel}
\citation{yu2007learning}
\citation{fyfe2000ica}
\citation{yu2007learning}
\citation{welling2005kcca}
\@writefile{toc}{\hbox { }}
\@writefile{toc}{\contentsline {chap}{\numberline {\hbox { }\hfill \bf  VIII.\hspace  {5pt}}{\bf  Kernel CCA (KCCA)}}{96}}
\@writefile{toc}{\hbox { }}
\newlabel{sec:kcca}{{VIII}{96}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}KCCA Derivation}{96}}
\newlabel{eq:kcca_lagr}{{8.1}{97}}
\newlabel{eq:kcca_lagr2}{{8.2}{97}}
\newlabel{eq:kcca_eig}{{8.4}{98}}
\newlabel{eq:ckcca}{{8.5}{98}}
\newlabel{eq:kcca_sol}{{8.6}{98}}
\newlabel{eq:ckcca_svd}{{8.7}{98}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Informative KCCA (IKCCA)}{99}}
\newlabel{eq:ikcca_sol}{{8.8}{99}}
\citation{yu2007learning}
\citation{nielsen2002multiset}
\citation{correa2010canonical}
\citation{deleus2011functional}
\citation{vinograde1950canonical}
\citation{steel1951minimum}
\citation{horst1961relations}
\citation{horst1961generalized}
\citation{kettenring1971canonical}
\citation{hotelling1936relations}
\citation{nielsen1994analysis}
\@writefile{toc}{\hbox { }}
\@writefile{toc}{\contentsline {chap}{\numberline {\hbox { }\hfill \bf  IX.\hspace  {5pt}}{\bf  Multiset CCA (MCCA)}}{100}}
\@writefile{toc}{\hbox { }}
\newlabel{sec:mcca}{{IX}{100}}
\citation{kettenring1971canonical}
\citation{nielsen1994analysis}
\citation{nielsen2002multiset}
\citation{nielsen1994analysis}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Mathematical Formulation of MCCA}{101}}
\newlabel{eq:opt_prob}{{9.1}{101}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.1}Constraint Functions, $h(x,R)$}{101}}
\newlabel{sec:constraints}{{9.1.1}{101}}
\citation{kettenring1971canonical}
\citation{horst1961relations}
\citation{kettenring1971canonical}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.2}Objective Functions, $J(\Phi (x))$}{102}}
\newlabel{sec:obj_func}{{9.1.2}{102}}
\citation{horst1961relations}
\citation{bach2003kernel}
\citation{kettenring1971canonical}
\citation{steel1951minimum}
\citation{kettenring1971canonical}
\citation{nielsen1994analysis}
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Theoretical and Empirical MCCA Derivations}{103}}
\@writefile{lot}{\contentsline {table}{\numberline {9.1}{\ignorespaces Notation used in MCCA\relax }}{104}}
\newlabel{tab:mcca_notation}{{9.1}{104}}
\citation{boumal2013manopt}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.1}Manopt Software for Optimization on Manifolds}{105}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.2}Successive Canonical Vectors}{105}}
\citation{nielsen2002multiset}
\citation{nielsen1994analysis}
\citation{nielsen1994analysis}
\citation{nielsen2002multiset}
\citation{kettenring1971canonical}
\citation{nielsen1994analysis}
\citation{deleus2011functional}
\citation{nielsen2002multiset}
\citation{via2005canonical}
\citation{nielsen1994analysis}
\citation{yu2007learning}
\citation{nielsen1994analysis}
\citation{nielsen1994analysis}
\citation{correa2010canonical}
\citation{kettenring1971canonical}
\citation{nielsen1994analysis}
\citation{nielsen1994analysis}
\citation{nielsen1994analysis}
\citation{nielsen1994analysis}
\citation{kettenring1971canonical}
\citation{nielsen1994analysis}
\citation{deleus2011functional}
\citation{via2005canonical}
\citation{nielsen1994analysis}
\citation{nielsen1994analysis}
\citation{nielsen1994analysis}
\citation{kettenring1971canonical}
\citation{nielsen1994analysis}
\citation{nielsen1994analysis}
\citation{bach2003kernel}
\citation{nielsen1994analysis}
\citation{nielsen1994analysis}
\citation{kettenring1971canonical}
\citation{nielsen1994analysis}
\citation{nielsen1994analysis}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.3}MCCA Summary}{106}}
\newlabel{sec:summary}{{9.2.3}{106}}
\@writefile{lot}{\contentsline {table}{\numberline {9.2}{\ignorespaces Summary of MCCA optimization problems. The objective functions are described in Section 9.1.2\hbox {}. The constraints are described in section 9.1.1\hbox {}. The eigenvalue problem column is the theoretical solution while the Empirical problem column describes how to solve the problem given empirical data. All eigenvalue problems solve the for the maximum eigenvalue-eigenvector pair except for the MINVAR problems, which solve for the minimum eigenvalue-eigenvector pair. The final column lists references which describe the MCCA optimization problem. \relax }}{107}}
\newlabel{tab:main_results}{{9.2}{107}}
\citation{sanderson2008biometric}
\citation{chaudhuri2009multi}
\citation{turnbull2007towards}
\citation{torres2007finding}
\citation{bertin2011million}
\citation{van1998handwritten}
\@writefile{toc}{\hbox { }}
\@writefile{toc}{\contentsline {chap}{\numberline {\hbox { }\hfill \bf  X.\hspace  {5pt}}{\bf  Future Work}}{108}}
\@writefile{toc}{\hbox { }}
\newlabel{sec:fw}{{X}{108}}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Real World Datasets}{108}}
\citation{hero2012hub}
\citation{asendorf2013performance}
\citation{nadakuditi2010fundamental}
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Future Work in CCA and ICCA}{109}}
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Future Work in RCCA and IRCCA}{109}}
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Future Work in KCCA and ICCA}{109}}
\@writefile{toc}{\contentsline {section}{\numberline {10.5}Future Work in MCCA}{110}}
\@writefile{toc}{\contentsline {section}{\numberline {10.6}Timeline}{110}}
\newlabel{tab:timeline}{{\caption@xref {tab:timeline}{ on input line 140}}{111}}
\@writefile{lot}{\contentsline {table}{\numberline {10.1}{\ignorespaces Proposed timeline with a set of milestones to ensure prompt completion of the dissertation.\relax }}{111}}
\@writefile{toc}{\contentsline {chapter}{APPENDICES}{112}}
\@writefile{loa}{\hbox { }}
\@writefile{loa}{\contentsline {appendix}{\numberline {A.}{\ignorespaces \rm  Theoretical and Empirical MCCA Derivations}}{113}}
\newlabel{sec:mcca_derivs}{{A}{113}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Problem 1a}{113}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}Theory}{113}}
\newlabel{eq:1a_prob}{{{\rm  A}.1}{113}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.2}Empirical}{114}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Problem 1b}{114}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.1}Theory}{114}}
\newlabel{eq:prob1b}{{{\rm  A}.2}{114}}
\newlabel{eq:rho1b}{{{\rm  A}.3}{114}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.2}Empirical}{115}}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Problem 1c}{115}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.1}Theory}{115}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.2}Empirical}{115}}
\@writefile{toc}{\contentsline {section}{\numberline {A.4}Problem 1d}{116}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4.1}Theory}{116}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4.2}Empirical}{117}}
\@writefile{toc}{\contentsline {section}{\numberline {A.5}Problem 2a}{117}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.5.1}Theory}{117}}
\newlabel{eq:2a_grad}{{{\rm  A}.4}{117}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.5.2}Empirical}{118}}
\@writefile{toc}{\contentsline {section}{\numberline {A.6}Problem 2b}{118}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.6.1}Theory}{118}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.6.2}Empirical}{118}}
\@writefile{toc}{\contentsline {section}{\numberline {A.7}Problem 2c}{119}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.7.1}Theory}{119}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.7.2}Empirical}{119}}
\@writefile{toc}{\contentsline {section}{\numberline {A.8}Problem 2d}{120}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.8.1}Theory}{120}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.8.2}Empirical}{120}}
\@writefile{toc}{\contentsline {section}{\numberline {A.9}Problem 3a}{121}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.9.1}Theory}{121}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.9.2}Empirical}{121}}
\@writefile{toc}{\contentsline {section}{\numberline {A.10}Problem 3b}{122}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.10.1}Theory}{122}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.10.2}Empirical}{122}}
\@writefile{toc}{\contentsline {section}{\numberline {A.11}Problem 3c}{123}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.11.1}Theory}{123}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.11.2}Empirical}{124}}
\@writefile{toc}{\contentsline {section}{\numberline {A.12}Problem 3d}{124}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.12.1}Theory}{124}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.12.2}Empirical}{125}}
\@writefile{toc}{\contentsline {section}{\numberline {A.13}Problem 4a}{125}}
\@writefile{toc}{\contentsline {section}{\numberline {A.14}Problem 4b}{125}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.14.1}Theory}{125}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.14.2}Empirical}{125}}
\@writefile{toc}{\contentsline {section}{\numberline {A.15}Problem 4c}{126}}
\@writefile{toc}{\contentsline {section}{\numberline {A.16}Problem 4d}{126}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.16.1}Theory}{126}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.16.2}Empirical}{126}}
\@writefile{toc}{\contentsline {section}{\numberline {A.17}Problems 5a-d Theory}{126}}
\newlabel{eq:genvar_cost}{{{\rm  A}.5}{126}}
\bibstyle{IEEEtran}
\newlabel{eq:genvar_grad}{{{\rm  A}.6}{127}}
\@writefile{toc}{\contentsline {section}{\numberline {A.18}Problem 5a Empirical}{127}}
\@writefile{toc}{\contentsline {section}{\numberline {A.19}Problem 5b Empirical}{127}}
\@writefile{toc}{\contentsline {section}{\numberline {A.20}Problem 5c Empirical}{127}}
\@writefile{toc}{\contentsline {section}{\numberline {A.21}Problem 5d Empirical}{127}}
\bibdata{IEEEabrv,thesis_bib,taes_msd/taes_useful,ieee_msd/IEEE_RMT_MSD_bib}
\@writefile{toc}{\contentsline {chapter}{BIBLIOGRAPHY}{128}}
